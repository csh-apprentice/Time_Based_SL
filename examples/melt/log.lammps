LAMMPS (2 Aug 2023 - Development)
OMP_NUM_THREADS environment is not set. Defaulting to 1 thread. (src/comm.cpp:98)
  using 1 OpenMP thread(s) per MPI task
package gpu 0
# 3d Lennard-Jones melt

units		lj
atom_style	atomic

lattice		fcc 0.8442
Lattice spacing in x,y,z = 1.6795962 1.6795962 1.6795962
region		box block 0 10 0 10 0 10
create_box	1 box
Created orthogonal box = (0 0 0) to (16.795962 16.795962 16.795962)
  1 by 1 by 1 MPI processor grid
create_atoms	1 box
Created 4000 atoms
  using lattice units in orthogonal box = (0 0 0) to (16.795962 16.795962 16.795962)
  create_atoms CPU = 0.001 seconds
mass		1 1.0

velocity	all create 3.0 87287 loop geom

pair_style	lj/cut/gpu 2.5
pair_coeff	1 1 1.0 1.0 2.5

neighbor	0.3 bin
neigh_modify	every 20 delay 0 check no

fix		1 all nve

#dump		id all atom 50 dump.melt

#dump		2 all image 25 image.*.jpg type type #		axes yes 0.8 0.02 view 60 -30
#dump_modify	2 pad 3

#dump		3 all movie 25 movie.mpg type type #		axes yes 0.8 0.02 view 60 -30
#dump_modify	3 pad 3

thermo		50
run		250

CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE

Your simulation uses code contributions which should be cited:

- GPU package (short-range, long-range and three-body potentials): doi:10.1016/j.cpc.2010.12.021, doi:10.1016/j.cpc.2011.10.012, doi:10.1016/j.cpc.2013.08.002, doi:10.1016/j.commatsci.2014.10.068, doi:10.1016/j.cpc.2016.10.020, doi:10.3233/APC200086

@Article{Brown11,
 author = {W. M. Brown and P. Wang and S. J. Plimpton and A. N. Tharrington},
 title = {Implementing Molecular Dynamics on Hybrid High Performance Computers---Short Range Forces},
 journal = {Comput.\ Phys.\ Commun.},
 year =    2011,
 volume =  182,
 pages =   {898--911},
 doi =     {10.1016/j.cpc.2010.12.021}
}

@Article{Brown12,
 author = {W. M. Brown and A. Kohlmeyer and S. J. Plimpton and A. N. Tharrington},
 title = {Implementing Molecular Dynamics on Hybrid High Performance Computers - Particle-Particle Particle-Mesh},
 journal = {Comput.\ Phys.\ Commun.},
 year =    2012,
 volume =  183,
 doi =     {10.1016/j.cpc.2011.10.012},
 pages =   {449--459}
}

@Article{Brown13,
 author = {W. M. Brown and Y. Masako},
 title = {Implementing Molecular Dynamics on Hybrid High Performance Computers---Three-Body Potentials},
 journal = {Comput.\ Phys.\ Commun.},
 year =    2013,
 volume =  184,
 pages =   {2785--2793},
 doi =     {10.1016/j.cpc.2013.08.002},
}

@Article{Trung15,
 author = {T. D. Nguyen and S. J. Plimpton},
 title = {Accelerating Dissipative Particle Dynamics Simulations for Soft Matter Systems},
 journal = {Comput.\ Mater.\ Sci.},
 year =    2015,
 doi =     {10.1016/j.commatsci.2014.10.068},
 volume =  100,
 pages =   {173--180}
}

@Article{Trung17,
 author = {T. D. Nguyen},
 title = {{GPU}-Accelerated {T}ersoff Potentials for Massively Parallel
    Molecular Dynamics Simulations},
 journal = {Comput.\ Phys.\ Commun.},
 year =    2017,
 doi =     {10.1016/j.cpc.2016.10.020},
 volume =  212,
 pages =   {113--122}
}

@inproceedings{Nikolskiy19,
 author = {V. Nikolskiy and V. Stegailov},
 title = {{GPU} Acceleration of Four-Site Water Models in {LAMMPS}},
 booktitle = {Proceedings of the International Conference on Parallel
    Computing (ParCo 2019), Prague, Czech Republic},
 doi =     {10.3233/APC200086},
 year =    2019
}

CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE-CITE

Generated 0 of 0 mixed pair_coeff terms from geometric mixing rule
Per MPI rank memory allocation (min/avg/max) = 2.383 | 2.383 | 2.383 Mbytes
   Step          Temp          E_pair         E_mol          TotEng         Press     
         0   3             -6.7733683      0             -2.2744933     -3.7033502    
        50   1.6842866     -4.8082497      0             -2.2824514      5.5666121    
       100   1.671258      -4.7875614      0             -2.2813012      5.6613898    
       150   1.6444736     -4.7471017      0             -2.281008       5.8614275    
       200   1.6471546     -4.7509113      0             -2.2807971      5.8805292    
       250   1.6645658     -4.7774302      0             -2.2812057      5.7526033    
Loop time of 0.0375745 on 1 procs for 250 steps with 4000 atoms

Performance: 2874286.149 tau/day, 6653.440 timesteps/s, 26.614 Matom-step/s
99.6% CPU use with 1 MPI tasks x 1 OpenMP threads

MPI task timing breakdown:
Section |  min time  |  avg time  |  max time  |%varavg| %total
---------------------------------------------------------------
Pair    | 0.030456   | 0.030456   | 0.030456   |   0.0 | 81.06
Neigh   | 1.237e-06  | 1.237e-06  | 1.237e-06  |   0.0 |  0.00
Comm    | 0.0040043  | 0.0040043  | 0.0040043  |   0.0 | 10.66
Output  | 7.9455e-05 | 7.9455e-05 | 7.9455e-05 |   0.0 |  0.21
Modify  | 0.0020048  | 0.0020048  | 0.0020048  |   0.0 |  5.34
Other   |            | 0.001029   |            |       |  2.74

Nlocal:           4000 ave        4000 max        4000 min
Histogram: 1 0 0 0 0 0 0 0 0 0
Nghost:           5506 ave        5506 max        5506 min
Histogram: 1 0 0 0 0 0 0 0 0 0
Neighs:              0 ave           0 max           0 min
Histogram: 1 0 0 0 0 0 0 0 0 0

Total # of neighbors = 0
Ave neighs/atom = 0
Neighbor list builds = 12
Dangerous builds not checked
Total wall time: 0:00:00
